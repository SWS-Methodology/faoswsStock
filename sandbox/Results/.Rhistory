plotGrid[, maxRow := which(maxDens == density), by = element]
plotGrid[, maxX := x[maxRow], by = element]
plotGrid[, distance := abs(x - maxX)]
p1 = ggplot(plotGrid[distance <= 10000, ], aes(x = x/1000, y = density, color = element)) + geom_line() +
geom_line(data = optimum, linetype = 2) +
facet_grid(. ~ element, scale = "free") +
labs(x = "Observed Wheat Value (1000's of tons)", y = "Probability Density") +
guides(color = FALSE) + coord_cartesian(ylim = c(-.00005, .005))
likelihood = function(params){
prod = params[1]
imp = params[2]
exp = params[3]
stock = params[4]
food = params[5]
feed = params[6]
seed = params[7]
loss = prod + imp - exp - feed - seed + stock - food
-dnorm(prod, mean = Prod, sd = ProdS, log = TRUE) -
dnorm(imp, mean = Imports, sd = ImportsS, log = TRUE) -
dnorm(exp, mean = Exports, sd = ExportsS, log = TRUE) -
dnorm(stock, mean = Stock, sd = StockS, log = TRUE) -
dnorm(feed, mean = Feed, sd = FeedS, log = TRUE) -
dnorm(seed, mean = Seed, sd = SeedS, log = TRUE) -
dnorm(loss, mean = Loss, sd = LossS, log = TRUE) -
dnorm(food, mean = Food, sd = FoodS, log = TRUE)
}
fit = optim(par = c(Prod, Imports, Exports, Stock, Food, Feed, Seed), fn = likelihood,
method = "L-BFGS-B")
loss = sum(fit$par[c(1:2, 4)]) - sum(fit$par[c(3, 5:7)])
## Reorder because of different definitions
optimum = data.table(element = names, x = c(fit$par, loss), SD, mean = mean)
optimum[, density := dnorm(x, mean = mean, SD)]
optimum[, density := 1]
temp = copy(optimum)[, density := 0]
optimum = rbind(optimum, temp)
p2 = ggplot(plotGrid[distance < 10000, ], aes(x = x/1000, y = density, color = element)) + geom_line() +
geom_line(data = optimum, linetype = 2) +
facet_grid(. ~ element, scale = "free") +
labs(x = "Adjusted Wheat Value (1000's of tons)", y = "Probability Density") +
guides(color = FALSE) + coord_cartesian(ylim = c(-.00005, .005))
png("~/Documents/Github/Working/Balancing Plot.png", width = 1000*1.2, height = 600*1.2)
grid.arrange(p1, p2)
dev.off()
## Loosely based on Wheat Production for US in 2011
library(ggplot2)
library(data.table)
library(gridExtra)
Prod = 54413
ProdS = 100
Imports = 3945
ImportsS = 200
Exports = 34369
ExportsS = 200
Stock = 7888
StockS = 2500
Food = 25041
FoodS = 400
Feed = 4898
FeedS = 1200
Seed = 1930
SeedS = 1000
Loss = .15 * Prod
LossS = 800
names = c("Production", "Imports", "Exports", "Stock", "Food", "Feed", "Seed", "Loss")
mean = c(Prod, Imports, Exports, Stock, Food, Feed, Seed, Loss)
SD = c(ProdS, ImportsS, ExportsS, StockS, FoodS, FeedS, SeedS, LossS)
Prod + Imports - Exports + Stock - Food - Feed - Seed - Loss
xGrid = seq(-10000, 80000, 10)
plotGrid = NULL
for(i in 1:length(mean)){
plotGrid = rbind(plotGrid, data.frame(x = xGrid, element = names[i],
density = dnorm(xGrid, mean = mean[i], sd = SD[i])))
}
# ggplot(plotGrid, aes(x = x, y = density)) + geom_line() +
#     facet_grid(. ~ element, scale = "free")
optimum = data.table(element = names, x = mean, SD)
optimum[, density := dnorm(0, mean = 0, SD)]
optimum[, density := 1]
temp = copy(optimum)[, density := 0]
optimum = rbind(optimum, temp)
plotGrid = data.table(plotGrid)
plotGrid[, maxDens := max(density), by = element]
plotGrid[, maxRow := which(maxDens == density), by = element]
plotGrid[, maxX := x[maxRow], by = element]
plotGrid[, distance := abs(x - maxX)]
p1 = ggplot(plotGrid[distance <= 10000, ], aes(x = x/1000, y = density, color = element)) + geom_line() +
geom_line(data = optimum, linetype = 2) +
facet_grid(. ~ element, scale = "free") +
labs(x = "Observed Wheat Value (1000's of tons)", y = "Probability Density") +
guides(color = FALSE) + coord_cartesian(ylim = c(-.00005, .005))
likelihood = function(params){
prod = params[1]
imp = params[2]
exp = params[3]
stock = params[4]
food = params[5]
feed = params[6]
seed = params[7]
loss = prod + imp - exp - feed - seed + stock - food
-dnorm(prod, mean = Prod, sd = ProdS, log = TRUE) -
dnorm(imp, mean = Imports, sd = ImportsS, log = TRUE) -
dnorm(exp, mean = Exports, sd = ExportsS, log = TRUE) -
dnorm(stock, mean = Stock, sd = StockS, log = TRUE) -
dnorm(feed, mean = Feed, sd = FeedS, log = TRUE) -
dnorm(seed, mean = Seed, sd = SeedS, log = TRUE) -
dnorm(loss, mean = Loss, sd = LossS, log = TRUE) -
dnorm(food, mean = Food, sd = FoodS, log = TRUE)
}
fit = optim(par = c(Prod, Imports, Exports, Stock, Food, Feed, Seed), fn = likelihood,
method = "L-BFGS-B")
loss = sum(fit$par[c(1:2, 4)]) - sum(fit$par[c(3, 5:7)])
## Reorder because of different definitions
optimum = data.table(element = names, x = c(fit$par, loss), SD, mean = mean)
optimum[, density := dnorm(x, mean = mean, SD)]
optimum[, density := 1]
temp = copy(optimum)[, density := 0]
optimum = rbind(optimum, temp)
p2 = ggplot(plotGrid[distance < 10000, ], aes(x = x/1000, y = density, color = element)) + geom_line() +
geom_line(data = optimum, linetype = 2) +
facet_grid(. ~ element, scale = "free") +
labs(x = "Adjusted Wheat Value (1000's of tons)", y = "Probability Density") +
guides(color = FALSE) + coord_cartesian(ylim = c(-.00005, .005))
png("~/Documents/Github/Working/Balancing Plot.png", width = 1000*1.2, height = 600*1.2)
grid.arrange(p1, p2)
dev.off()
extractionRate = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/extractionRate2011.csv")
library(data.table)
extractionRate = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/extractionRate2011.csv")
shares = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/shares2011.csv")
shares
extractionRateData = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/extractionRate2011.csv")
sharesData = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/shares2011.csv")
setnames(extractionRateData,
old = c("measuredItemFS", "timePointYears",
"Value", "flagFaostat"),
new = c("measuredItemChildFS", "timePointYearsSP",
"extractionRate", "flagExtractionRate"))
extractionRateData
setnames(extractionRateData,
old = c("measuredItemFS", "timePointYears",
"Value", "Status"),
new = c("measuredItemChildFS", "timePointYearsSP",
"extractionRate", "flagExtractionRate"))
shareData
shareData = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/shares2011.csv")
shareData
summary(shareData)
setnames(shareData, old = "Value", new = "share")
edges = merge(shareData, extractionRateData,
by = c("geographicAreaFS", "measuredItemChildFS",
"timePointYearsSP"))
edges
shareData
extractionRateData
shareData
extractionRateData
extractionRateData = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/extractionRate2011.csv")
shareData = fread("~/Documents/Github/sws_standardization/faoswsStandardization/data/shares2011.csv")
setnames(extractionRateData,
old = c("measuredItemFS", "timePointYears",
"Value", "Status"),
new = c("measuredItemChildFS", "timePointYearsSP",
"extractionRate", "flagExtractionRate"))
setnames(shareData, old = "Value", new = "share")
edges = merge(shareData, extractionRateData,
by = c("geographicAreaFS", "measuredItemChildFS",
"timePointYearsSP"))
edges
extractionRateData
edges
commodityTree = merge(shareData, extractionRateData,
by = c("geographicAreaFS", "measuredItemChildFS",
"timePointYearsSP"))
commodityTree
save(commodityTree, file = "~/Documents/Github/sws_standardization/faoswsStandardization/data/commodityTree2011.RData")
commodityTree
load("~/Documents/Github/sws_standardization/faoswsStandardization/data/commodityTree2011.RData"))
load("~/Documents/Github/sws_standardization/faoswsStandardization/data/commodityTree2011.RData")
commodityTree
nodes <- data.table(id = 1:10, value = 1)
nodes[, Quan := 100]
nodeData = copy(nodes)
nodeData
commodityTree
parentColname = "measuredItemParentFS"
childColname = "measuredItemChildFS"
extractionColname = "extractionRate"
shareColname = "share"
byKey = NULL
nSigma
nSigma = 2
stopifnot(is(commodityTree, "data.table"))
stopifnot(c(parentColname, childColname, extractionColname, shareColname)
%in% colnames(commodityTree))
## Estimate the mean and variance for each unique year/commodity pair
byKey = c(byKey, parentColname, childColname)
huber = function(...){
values = try(MASS::huber(...))
if(is(values, "try-error"))
return(list(mu = NA, s = NA))
return(values)
}
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
huber = function(...){
values = suppressMessages(try(MASS::huber(...)))
if(is(values, "try-error"))
return(list(mu = NA, s = NA))
return(values)
}
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
huber = function(...){
values = try(MASS::huber(...), silent = TRUE)
if(is(values, "try-error"))
return(list(mu = NA, s = NA))
return(values)
}
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree
?try
commodityTree[, c("meanRate", "varianceRate") :=
huber(get(extractionColname), k = 1.5), by = byKey]
huber = function(...){
values = try(MASS::huber(...), silent = TRUE)
if(is(values, "try-error"))
return(list(mu = NA_real_, s = NA_real_))
return(values)
}
commodityTree[, c("meanRate", "varianceRate") :=
huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree
commodityTree
qplot(commodityTree[measuredItemChild == "16", extractionRate]
)
commodityTree[measuredItemChild == "16", extractionRate]
commodityTree[measuredItemChildFS == "16", extractionRate]
qplot(commodityTree[measuredItemChildFS == "16", extractionRate])
library(ggplot2)
qplot(commodityTree[measuredItemChildFS == "16", extractionRate])
qplot(commodityTree[measuredItemChildFS == "17", extractionRate])
commodityTree[measuredItemParentFS == "16", ]
qplot(commodityTree[measuredItemChildFS == "18", extractionRate])
commodityTree[measuredItemChildFS == "18", extractionRate]
commodityTree[measuredItemChildFS == "20", extractionRate]
commodityTree[measuredItemChildFS == "22", extractionRate]
commodityTree[measuredItemChildFS == "110", extractionRate]
commodityTree[, c("meanRate", "varianceRate") :=
huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree
commodityTree[abs(normalScore) > 5, ]
commodityTree[measuredItemChildFS == "57", extractionRate]
commodityTree[measuredItemChildFS == "57", extractionRate]
qplot(commodityTree[measuredItemChildFS == "57", extractionRate])
data("commodityTree")
commodityTree
qplot(commodityTree[measuredItemChildFS == "57", extractionRate])
commodityTree[measuredItemChildFS == "57", extractionRate]
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree
commodityTree[, meanRate := NULL]
commodityTree[, varianceRate := NULL]
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree
byKey = c("measuredItemChildFS", "measuredItemParentFS")
byKey = c("measuredItemChildFS", "measuredItemParentFS")
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree[normalScore > 2, extractionQuantile := rank(normalScore),
by = byKey]
commodityTree
commodityTree[measuredItemChildFS == "57", ]
byKey
byKey = c("measuredItemChildFS", "measuredItemParentFS")
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree[, normalScore := (extractionRate - meanRate)/varianceRate]
commodityTree
commodityTree[measuredItemChildFS == "57",
]
extractionColname
commodityTree[, c("meanRate", "varianceRate") :=
MASS::huber(extractionRate, k = 1.5), by = byKey]
commodityTree[measuredItemChildFS == "57",
]
## Overwrite the default huber function so it returns NA/NA instead of
## errors when the MAD (Median Absolute Deviation) can't be estimated.
huber = function(...){
values = try(MASS::huber(...), silent = TRUE)
if(is(values, "try-error"))
return(list(mu = NA_real_, s = NA_real_))
return(values)
}
subset = commodityTree[measuredItemChildFS == "57", ]
byKey = c("measuredItemChildFS", "measuredItemParentFS")
subset
subset[, c("meanRate", "varianceRate") :=
huber(extractionRate, k = 1.5), by = byKey]
subset
subset[, normalScore := (extractionRate - meanRate)/varianceRate]
subset
subset[normalScore > 2, extractionQuantile := rank(normalScore),
subset[normalScore > 2, extractionQuantile := rank(normalScore)]
subset
commodityTree[, extractionQuantile := rank(normalScore), by = byKey]
commodityTree
commodityTree[, extractionQuantile := rank(normalScore)/.N, by = byKey]
commodityTree
rank(1:10)/10
(rank(1:10)-.5)/10
commodityTree[, extractionQuantile := (rank(normalScore)-.5)/.N, by = byKey]
commodityTree
commodityTree[, extractionQuantile := (rank(normalScore) - .5)/.N,
by = byKey]
commodityTree
commodityTree
qnorm(0)
commodityTree[, c("meanRate", "sdRate") :=
huber(get(extractionColname), k = 1.5), by = byKey]
commodityTree
commodityTree[, varianceRate := NULL]
commodityTree[, normalScore := (extractionRate - meanRate)/sdRate]
commodityTree[, extractionQuantile := (rank(normalScore) - .5)/.N,
by = byKey]
commodityTree[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
commodityTree
commodityTree[normalScore > nSigma, extractionRate := normalValue]
commodityTree
source('~/Documents/Github/sws_standardization/faoswsStandardization/adjustCommodityTree.R')
subset[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
subset = commodityTree[measuredItemChildFS == "57", ]
subset[, c("meanRate", "sdRate") :=
huber(extractionRate, k = 1.5), by = byKey]
subset[, normalScore := (extractionRate - meanRate)/varianceRate]
subset[, extractionQuantile := rank(normalScore)]
subset[, normalScore := (extractionRate - meanRate)/sdRate]
subset[, extractionQuantile := rank(normalScore)]
subset[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
subset
subset = commodityTree[measuredItemChildFS == "57", ]
subset[, c("meanRate", "sdRate") :=
huber(extractionRate, k = 1.5), by = byKey]
subset[, normalScore := (extractionRate - meanRate)/sdRate]
subset[, extractionQuantile := (rank(normalScore) - .5)/.N, by = byKey]
subset[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
subset
ggplot(subset, aes(x = extractionRate, y = normalValue)) + geom_point()
histRight = qplot(subset$normalValue)
histRight
histTop = qplot(subset$extractionRate) + labs(x = "", y = "")
histRight = qplot(subset$normalValue) + labs(x = "", y = "")
histTop
histRight
subset$normalValue
subset$extractionRate
subset[, extractionQuantile
]
qplot(subset[, extractionQuantile])
subset[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
subset
histTop = qplot(subset$extractionRate) + labs(x = "", y = "")
histRight = qplot(subset$normalValue) + labs(x = "", y = "")
histTop
histRight
subset[, extractionQuantile := (rank(normalScore) - .5)/.N, by = byKey]
rank
subset[, extractionQuantile := (rank(normalScore) - .5)/.N, by = byKey]
subset[, normalValue := qnorm(extractionQuantile, mean = meanRate,
sd = sdRate)]
histTop = qplot(subset$extractionRate) + labs(x = "", y = "")
histRight = qplot(subset$normalValue) + labs(x = "", y = "")
ggplot(subset, aes(x = extractionRate, y = normalValue)) + geom_point()
library(gridExtra)
grid.arrange(histTop, empty, scatter, histRight, ncol=2, nrow=2,
widths=c(4, 1), heights=c(1, 4))
empty = ggplot()+geom_point(aes(1,1), colour="white")+
opts(axis.ticks=theme_blank(),
panel.background=theme_blank(),
axis.text.x=theme_blank(), axis.text.y=theme_blank(),
axis.title.x=theme_blank(), axis.title.y=theme_blank())
grid.arrange(histTop, empty, scatter, histRight, ncol=2, nrow=2,
widths=c(4, 1), heights=c(1, 4))
empty = ggplot()+geom_point(aes(1,1), colour="white")+
theme(axis.ticks=theme_blank(),
panel.background=theme_blank(),
axis.text.x=theme_blank(), axis.text.y=theme_blank(),
axis.title.x=theme_blank(), axis.title.y=theme_blank())
empty = ggplot()+geom_point(aes(1,1), colour="white")+
theme(axis.ticks=element_blank(),
panel.background=element_blank(),
axis.text.x=element_blank(), axis.text.y=element_blank(),
axis.title.x=element_blank(), axis.title.y=element_blank())
grid.arrange(histTop, empty, scatter, histRight, ncol=2, nrow=2,
widths=c(4, 1), heights=c(1, 4))
scatter = ggplot(subset, aes(x = extractionRate, y = normalValue)) +
geom_point()
grid.arrange(histTop, empty, scatter, histRight, ncol=2, nrow=2,
widths=c(4, 1), heights=c(1, 4))
histRight = qplot(subset$normalValue) + labs(x = "", y = "") +
coord_flip()
scatter = ggplot(subset, aes(x = extractionRate, y = normalValue)) +
geom_point()
empty = ggplot()+geom_point(aes(1,1), colour="white")+
theme(axis.ticks=element_blank(),
panel.background=element_blank(),
axis.text.x=element_blank(), axis.text.y=element_blank(),
axis.title.x=element_blank(), axis.title.y=element_blank())
grid.arrange(histTop, empty, scatter, histRight, ncol=2, nrow=2,
widths=c(4, 1), heights=c(1, 4))
library(data.table)
library(ggplot2)
library(magrittr)
library(zoo)
d = fread("~/Documents/Github/faoswsStock/tests/Data/usaStockVariabilityFAOSTAT.csv")
setwd("~/Documents/Github/faoswsStock/tests/Results/")
d[, .N, c("ItemCode", "Year")][, .N, N]
coeff = vector("list", 20)
for(windowLength in 1:20){
d[, pastStockSum := c(rep(NA, windowLength - 1),
rollsum(Value, k = windowLength)),
by = ItemCode]
## pastStockSum currently includes current line.  Must bump back one.
d[, pastStockSum := c(NA, pastStockSum[-length(pastStockSum)]),
by = ItemCode]
ggsave(paste0("Stock_plots_summed_lag_", windowLength, ".png"),
ggplot(d, aes(x = pastStockSum, y = Value)) + geom_point() +
facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0),
width = 16, height = 16)
coeff[[windowLength]] = d[, lm(Value ~ pastStockSum + 0)$coeff[1],
by = "ItemName"]
coeff[[windowLength]]$windowLength = windowLength
}
coeff = vector("list", 20)
i = 15
d[, pastStockSum := c(rep(NA, windowLength - 1),
rollsum(Value, k = windowLength)),
by = ItemCode]
d
d[, pastStockSum := c(NA, pastStockSum[-length(pastStockSum)]),
by = ItemCode]
ggplot(d, aes(x = pastStockSum, y = Value)) + geom_point() +
facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0)
d
table(d$ItemName
)
wheatItems = c("Wheat and products", "Maize and products",
"Cereals - Excluding Beer", "Cereals, Other",
"Barley and products")
wheatItems
d[ItemName %in% wheatItems, ]
windowLength
windowLength = 15
wheatItems = c("Wheat and products", "Maize and products",
"Cereals - Excluding Beer", "Cereals, Other",
"Barley and products")
d
d[ItemName %in% wheatItems, ]
d[, pastStockSum := c(rep(NA, windowLength - 1),
rollsum(Value, k = windowLength)),
by = ItemCode]
## pastStockSum currently includes current line.  Must bump back one.
d[, pastStockSum := c(NA, pastStockSum[-length(pastStockSum)]),
by = ItemCode]
d
d[ItemName %in% wheatItems, ]
ggplot(d[ItemName %in% wheatItems, ], aes(x = pastStockSum, y = Value)) +
geom_point() + facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0)
paste0("Stock_wheat_summed_lag_", windowLength, ".png")
ggsave(paste0("Stock_wheat_summed_lag_", windowLength, ".png"),
ggplot(d[ItemName %in% wheatItems, ], aes(x = pastStockSum, y = Value)) +
geom_point() + facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0),
width = 16, height = 16)
ggsave(paste0("Stock_wheat_summed_lag_", windowLength, ".png"),
ggplot(d[ItemName %in% wheatItems, ], aes(x = pastStockSum, y = Value)) +
geom_point() + facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0),
width = 8, height = 8)
ggsave(paste0("Stock_wheat_summed_lag_", windowLength, ".png"),
ggplot(d[ItemName %in% wheatItems, ], aes(x = pastStockSum, y = Value)) +
geom_point() + facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0) +
labs(x = "Sum of previous 15 stock changes",
y = "Current stock change"),
width = 8, height = 8)
ggsave(paste0("Stock_cereal_summed_lag_", windowLength, ".png"),
ggplot(d[ItemName %in% wheatItems, ], aes(x = pastStockSum, y = Value)) +
geom_point() + facet_wrap( ~ ItemName, scale = "free") +
geom_smooth(method = "lm", formula = y ~ x + 0) +
labs(x = "Sum of previous 15 stock changes",
y = "Current stock change"),
width = 8, height = 8)
